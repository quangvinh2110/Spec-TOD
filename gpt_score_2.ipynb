{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b1f75db-fac3-46f3-820b-d0070c4716fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_DIALOGUE= \"\"\"You are a powerful and accurate assistant in checking the quality of a predicted answer. You will be given a dialogue between human and AI, which contains user utterance, assistant response and reference label. \n",
    "### Please evaluate the dialogue based on the following criteria and give a score from 0 to 5 for each criterion:\n",
    "1) Interesting:  Are the responses of AI interesting.\n",
    "2) Engaging: Are the responses of AI engaging.\n",
    "3) Understandable: Are the responses of AI understandable.\n",
    "4) Relevant: Are the responses of AI relevant to the conversation. \n",
    "5) Correct: Are the responses of AI correct to conversations.\n",
    "6) Appropriate: Are the responses of AI semantically appropriate.\n",
    "7) Fluently: Are the responses of AI fluently written.\n",
    "8) Direct: Are the responses of AI directly answer request from human.\n",
    "### Dialogue: {{dialog}}\n",
    "### Note:\n",
    "Respond in the following JSON format and do NOT generate unnecessary details beyond the JSON object\n",
    "{\n",
    "    \"score\": \"an integer score range from 0 to 5\"\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e09e49-100c-4850-8573-09e87d192818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/pptod-main/E2E_TOD/inference_result/base/10percent/inference_result_e2e_evaluation_inform_82.0_success_65.0_bleu_14.19_combine_score_87.69.json\",\"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2607fe82-558e-4005-ba78-43cdb597d332",
   "metadata": {},
   "outputs": [],
   "source": [
    "format_data = {}\n",
    "for o in data:\n",
    "    if o[\"dial_id\"] not in format_data:\n",
    "        format_data[o[\"dial_id\"]] = [o]\n",
    "    else:\n",
    "        format_data[o[\"dial_id\"]].append(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c79ac9e-89aa-4807-98e5-3769e05e9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.notebook import tqdm\n",
    "from openai import OpenAI\n",
    "import multiprocessing\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"True\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://10.254.138.191:9002/v1\",\n",
    "    api_key=\"EMPTY\",\n",
    ")\n",
    "\n",
    "MODEL_NAME = \"/home/NLP_CORE/HUB_LLM/Meta-Llama-3-70B-Instruct/\"\n",
    "def get_tokenizer(model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        trust_remote_code=True,\n",
    "    )\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.truncation_side = 'left'\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    return tokenizer\n",
    "\n",
    "def generate(prompt, max_new_tokens=256):\n",
    "    response = client.completions.create(\n",
    "        model=\"Meta-Llama-3-70B-Instruct\",\n",
    "        # model=\"Qwen2-72B-Instruct\",\n",
    "        prompt=prompt,\n",
    "        max_tokens=max_new_tokens,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        stream=False\n",
    "    )\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df72409c-14b1-4967-9edf-41e65cdf9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogues = []\n",
    "for item in format_data:\n",
    "    turns = format_data[item]\n",
    "    dia = \"\"\n",
    "    for turn in turns:\n",
    "        dia += \"user: \" + turn[\"user\"] + '\\n'\n",
    "        dia += \"assistant: \" + turn[\"resp_gen\"] + '\\n'\n",
    "        dia += \"reference: \" + turn[\"resp\"] + '\\n'\n",
    "    dialogues.append(dia)\n",
    "# for o in format_data:\n",
    "#     print(format_data[o])\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "18dd0e1b-cbee-480d-acff-7012b167eabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"user: please find a restaurant called nusha .\\nassistant: [value_name] is a [value_food] restaurant in the [value_area] . would you like their address ?\\nreference: i do n't seem to be finding anything called [value_name] . what type of food does the restaurant serve ?\\nuser: i am not sure of the type of food but could you please check again and see if you can find it ? thank you .\\nassistant: [value_name] is a [value_food] restaurant in the [value_area] . would you like their address ?\\nreference: could you double check that you have spelled the name correctly ? the closest i can find is [value_name] .\\nuser: it is not a restaurant , it is an attraction . nusha .\\nassistant: it is an attraction . would you like to book a table ?\\nreference: oh its okay . that is an [value_type] type located in the [value_area] at [value_address] . do you need their phone number ?\\nuser: no , but please confirm their address again and their postcode .\\nassistant: yes , their address is [value_address] . their postcode is [value_postcode] .\\nreference: their address is [value_address] the postcode is [value_postcode] . is their anything else i can do for you ?\\nuser: i want indian food in the center area .\\nassistant: [value_name] is a [value_food] restaurant in the [value_area] . would you like their address ?\\nreference: there are [value_choice] [value_food] restaurant -s in [value_area] what price range do you want ?\\nuser: i am looking for expensive indian food .\\nassistant: [value_name] is a [value_food] restaurant in the [value_area] . would you like their address ?\\nreference: [value_name] is an [value_price] restaurant that serves [value_food] food\\nuser: can i get the address for saffron brasserie ?\\nassistant: [value_name] is located at [value_address] .\\nreference: the address is [value_address]\\nuser: can i clarify that it was indian food and not italian food please ?\\nassistant: yes , it is in the [value_area] . would you like me to book a table ?\\nreference: yes , [value_name] is [value_food] food .\\nuser: thank you that is all the information i need at the moment .\\nassistant: thank you for using cambridge towninfo . goodbye .\\nreference: i hope i have been of help\\nuser: you have . thank you . goodbye .\\nassistant: thank you for using cambridge towninfo . goodbye .\\nreference: i am glad to help . enjoy your stay !\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogues[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb2b6da6-6a8d-4afa-88f9-6c1817fe7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(string):\n",
    "    first = string.find(\"{\")\n",
    "    last = string.rfind(\"}\")\n",
    "    # print(string[first:last+1])\n",
    "    return json.loads(string[first:last+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d018c463-67e2-4896-a1b4-c65bcd37ec76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac6334d6f284793932dc6836e41a461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n",
      "sai format\n"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "for i in tqdm(range(len(dialogues))):\n",
    "    tmp = generate(PROMPT_DIALOGUE.replace(\"{{dialog}}\",dialogues[i]))\n",
    "    try:\n",
    "        tmp = load_json(tmp)\n",
    "        result[i] = tmp\n",
    "    except:\n",
    "        result[i] = tmp\n",
    "        print(\"sai format\")\n",
    "        pass\n",
    "# print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2c54b84-d62d-472d-abf2-34ab1c2cb938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Interesting': 2,\n",
       " 'Engaging': 1,\n",
       " 'Understandable': 3,\n",
       " 'Relevant': 3,\n",
       " 'Correct': 2,\n",
       " 'Appropriate': 3,\n",
       " 'Fluently': 3,\n",
       " 'Direct': 2}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "912d0bd3-dd68-4297-980b-8629eebce111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result[0]\n",
    "agg = {\n",
    "'Interesting': 0,'Engaging': 0,'Understandable': 0,\n",
    " 'Relevant': 0,\n",
    " 'Correct': 0,\n",
    " 'Appropriate': 0,\n",
    " 'Fluently': 0,\n",
    " 'Direct': 0}\n",
    "for i in range(1000):\n",
    "    # print(o)\n",
    "    o = result[i]\n",
    "    # print(o)\n",
    "    try:\n",
    "        for key in agg:\n",
    "            agg[key] += o[key]\n",
    "    except:\n",
    "        for key in agg:\n",
    "            agg[key] += 1\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f65a2257-79aa-4ba6-9277-21dba6190aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"gpt_score_llama3.json\",\"w\") as f:\n",
    "    json.dump(result, f,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
